# see https://docs.mcp-agent.com/reference/configuration
$schema: ../../../schema/mcp-agent.config.schema.json

name: deep_research_agent
execution_engine: asyncio

logger:
  transports: [file]
  level: debug
  progress_display: true
  path_settings:
    # Logs rel
    path_pattern: "../logs/deep-research-agent-{unique_id}.jsonl"
    unique_id: "timestamp" # Options: "timestamp" or "session_id"
    timestamp_format: "%Y%m%d_%H%M%S"

mcp:
  servers:
    # Examples using Context Forge/MCP Gateway as the proxy for the first
    # three (external) services. A local test server will have the base URL
    # "http://localhost:4444", by default, which we use here. Replace this
    # value with the correct URL for your Context Forge deployment.
    fetch:
      command: "npx"
      args: ["-y", "mcp-remote", "http://localhost:4444/mcp/fetch", 
             "--header", "Authorization: Bearer ${MCPGATEWAY_BEARER_TOKEN}"]
    yfmcp:
      command: "npx"
      args: ["-y", "mcp-remote", "http://localhost:4444/mcp/yfmcp",
             "--header", "Authorization: Bearer ${MCPGATEWAY_BEARER_TOKEN}"]
    financial-datasets:
      command: "npx"
      args: ["-y", "mcp-remote", "http://localhost:4444/mcp/financial-datasets",
             "--header", "Authorization: Bearer ${MCPGATEWAY_BEARER_TOKEN}"]

    # Local services that don't use the gateway.
    filesystem:
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-filesystem", "."]
    excel_writer:
      command: "uvx"
      args: ["excel-mcp-server", "stdio"]
      
# Since Ollama and OpenAI use the same internal code path, i.e.,
# mcp-agent's `OpenAIAugmentedLLM`, you MUST uncomment the correct "openai"
# definition here and comment out the other one!
# Eliminating this manual step is TBD.

# Use this for OpenAI inference:
openai:
  default_model: "gpt-4o-mini"
  reasoning_effort: "medium"
  base_url: "https://api.openai.com/v1"
  
# Use this for ollama inference. Change the model, too!
# openai:
#   default_model: "gpt-oss:20b"
#   reasoning_effort: "medium"
#   base_url: "http://localhost:11434/v1"
#   api_key: "ignored"

anthropic:
  default_model: "claude-3-5-sonnet-20241022"
